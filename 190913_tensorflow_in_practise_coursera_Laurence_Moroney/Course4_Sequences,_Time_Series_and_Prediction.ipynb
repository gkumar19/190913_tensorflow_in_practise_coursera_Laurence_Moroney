{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course4: Sequences, Time Series and Prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc3RFVnPvt96",
        "colab_type": "text"
      },
      "source": [
        "Week1: Generic time series function creation and keras metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsVFO1FvvmyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "from matplotlib import style\n",
        "style.use('seaborn')\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "def plot_series(time, series, format = '-', start = 0 , end = None):\n",
        "    plt.plot(time[start:end],series[start:end], format)\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('values')\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope = 0):\n",
        "    return slope*time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    return np.where(season_time<0.4,\n",
        "                    np.cos(season_time)*5,\n",
        "                    np.exp(season_time))\n",
        "\n",
        "def seasonality(time, period, phase = 0, amplitude = 1):\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return  seasonal_pattern(season_time) * amplitude\n",
        "\n",
        "def noise(time, noise_level = 1, seed = None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.rand(len(time)) * noise_level\n",
        "\n",
        "time = np.arange(4*365+1, dtype = 'float')\n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.2\n",
        "noise_level = 5\n",
        "series = baseline + trend(time,slope) + seasonality(time = time,period = 365, phase = 0,amplitude = amplitude) + noise(time, noise_level = noise_level, seed = 1)\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10,6))\n",
        "plot_series(time,series)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "time_train, time_test, series_train, series_test = train_test_split(time, series, test_size=0.33, shuffle = False)\n",
        "\n",
        "naive_forecast = series[len(time_train)-1:-1]\n",
        "plt.figure('test', figsize = (10,6))\n",
        "plot_series(time_test,series_test,end = 150)\n",
        "plot_series(time_test,naive_forecast, end = 150)\n",
        "\n",
        "print('mae_naive' , keras.metrics.mean_absolute_error(series_test,naive_forecast).numpy())\n",
        "print('mse_naive' , keras.metrics.mean_squared_error(series_test,naive_forecast).numpy())\n",
        "\n",
        "def moving_average_forecast(series, window_size = 1):\n",
        "    forecast = []\n",
        "    for i in range(len(series) - window_size):\n",
        "        forecast.append(np.mean(series[i:i+window_size]))\n",
        "    return np.array(forecast)\n",
        "\n",
        "moving_average = moving_average_forecast(series, 30)[len(time_train)-30:]\n",
        "plt.figure('moving_average', figsize = (10,6))\n",
        "plot_series(time_test, series_test)\n",
        "plot_series(time_test,moving_average)\n",
        "\n",
        "print('mae_moving',keras.metrics.mean_absolute_error(series_test, moving_average).numpy())\n",
        "print('mse_moving',keras.metrics.mean_squared_error(series_test, moving_average).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsG4B99UwA8_",
        "colab_type": "text"
      },
      "source": [
        "Week2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbPrjpPwCL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "from matplotlib import style\n",
        "style.use('seaborn')\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "\n",
        "for tensors in dataset:\n",
        "    print(tensors)\n",
        "\n",
        "dataset = dataset.window(5, shift = 1,stride = 1, drop_remainder = True)\n",
        "for window_dataset in dataset:\n",
        "    for val in window_dataset:\n",
        "        print(val.numpy(), end = '-')\n",
        "    print()\n",
        "\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "for window in dataset:\n",
        "    print(window.numpy())\n",
        "\n",
        "dataset = dataset.map(lambda window: (window[:-1],window[-1:]))\n",
        "for x,y in dataset:\n",
        "    print(x.numpy(),y.numpy())\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size = 10)\n",
        "for x,y in dataset:\n",
        "    print(x.numpy(),y.numpy())\n",
        "\n",
        "dataset = dataset.batch(2).prefetch(1)\n",
        "for x,y in dataset:\n",
        "    print(x.numpy(),y.numpy())\n",
        "\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift = 1,drop_remainder = True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "    dataset = dataset.map(lambda window: (window[:-1],window[-1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1).repeat()\n",
        "    return dataset\n",
        "\n",
        "def plot_series(time, series, format = '-', start = 0 , end = None):\n",
        "    plt.plot(time[start:end],series[start:end], format)\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('values')\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope = 0):\n",
        "    return slope*time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    return np.where(season_time<0.4,\n",
        "                    np.cos(season_time)*5,\n",
        "                    np.exp(season_time))\n",
        "\n",
        "def seasonality(time, period, phase = 0, amplitude = 1):\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return  seasonal_pattern(season_time) * amplitude\n",
        "\n",
        "def noise(time, noise_level = 1, seed = None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.rand(len(time)) * noise_level\n",
        "\n",
        "time = np.arange(4*365+1, dtype = 'float')\n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.2\n",
        "noise_level = 5\n",
        "series = baseline + trend(time,slope) + seasonality(time = time,period = 365, phase = 0,amplitude = amplitude) + noise(time, noise_level = noise_level, seed = 1)\n",
        "test_test_split = 1000\n",
        "\n",
        "time_train = time[:test_test_split]\n",
        "series_train = series[:test_test_split]\n",
        "time_test = time[test_test_split:]\n",
        "series_test = series[test_test_split:]\n",
        "\n",
        "window_size = 10\n",
        "batch_size = 30\n",
        "shuffle_batch_size = 1000\n",
        "dataset2 = windowed_dataset(series_train,window_size,batch_size,shuffle_batch_size)\n",
        "\n",
        "l0 = tf.keras.layers.Dense(1,input_shape = [window_size])\n",
        "model = tf.keras.models.Sequential([l0])\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 *10**(epoch/2000))\n",
        "model.compile(loss = 'mse', optimizer= tf.keras.optimizers.SGD(lr=1e-6 ,momentum = 0.9))\n",
        "history = model.fit(dataset2,epochs = 1001, steps_per_epoch=1, callbacks=[lr_schedule])\n",
        "\n",
        "lrs = 1e-8 *10**(np.arange(1001)/2000)\n",
        "plt.semilogx(lrs, history.history['loss'])\n",
        "\n",
        "print(l0.get_weights())\n",
        "\n",
        "forecast = []\n",
        "\n",
        "for time in range(len(series) - window_size):\n",
        "  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "forecast = forecast[test_test_split-window_size:]\n",
        "results = np.array(forecast)[:, 0, 0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plot_series(time_test, series_test)\n",
        "plot_series(time_test, results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb0B_BTwDGL0",
        "colab_type": "text"
      },
      "source": [
        "Week3: Lambda Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtcrtWhzDI_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,axis = -1), input_shape = [None]),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(40, return_sequences=True)),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(40)),\n",
        "                                    tf.keras.layers.Dense(1),\n",
        "                                    tf.keras.layers.Lambda(lambda x: x*10)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFgsFxHfrDNM",
        "colab_type": "text"
      },
      "source": [
        "Week4: dataset2 has got some issue, rest all is fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCo0jHImDJ2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "from matplotlib import style\n",
        "style.use('seaborn')\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "\n",
        "for tensors in dataset:\n",
        "    print(tensors)\n",
        "\n",
        "dataset = dataset.window(5, shift = 1,stride = 1, drop_remainder = True)\n",
        "for window_dataset in dataset:\n",
        "    for val in window_dataset:\n",
        "        print(val.numpy(), end = ',')\n",
        "    print()\n",
        "\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "for window in dataset:\n",
        "    print(window.numpy())\n",
        "\n",
        "dataset = dataset.map(lambda window: (window[:-1],window[-1:]))\n",
        "for x,y in dataset:\n",
        "    print(x.numpy(),y.numpy())\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size = 10)\n",
        "for x,y in dataset:\n",
        "    print(x.numpy(),y.numpy())\n",
        "\n",
        "dataset = dataset.batch(2).prefetch(1)\n",
        "for x,y in dataset:\n",
        "    print(x.numpy(),y.numpy())\n",
        "\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift = 1,drop_remainder = True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "    dataset = dataset.map(lambda window: (window[:-1],window[-1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1).repeat()\n",
        "    return dataset\n",
        "\n",
        "def model_forecast(model,series,window_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
        "    dataset = dataset.batch(32).prefetch(1)\n",
        "    return model.predict(dataset)\n",
        "\n",
        "def plot_series(time, series, format = '-', start = 0 , end = None):\n",
        "    plt.plot(time[start:end],series[start:end], format)\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('values')\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope = 0):\n",
        "    return slope*time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    return np.where(season_time<0.4,\n",
        "                    np.cos(season_time)*5,\n",
        "                    np.exp(season_time))\n",
        "\n",
        "def seasonality(time, period, phase = 0, amplitude = 1):\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return  seasonal_pattern(season_time) * amplitude\n",
        "\n",
        "def noise(time, noise_level = 1, seed = None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.rand(len(time)) * noise_level\n",
        "\n",
        "time = np.arange(4*365+1, dtype = 'float')\n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.2\n",
        "noise_level = 5\n",
        "series = baseline + trend(time,slope) + seasonality(time = time,period = 365, phase = 0,amplitude = amplitude) + noise(time, noise_level = noise_level, seed = 1)\n",
        "test_test_split = 1000\n",
        "\n",
        "time_train = time[:test_test_split]\n",
        "series_train = series[:test_test_split]\n",
        "time_test = time[test_test_split:]\n",
        "series_test = series[test_test_split:]\n",
        "\n",
        "window_size = 10\n",
        "batch_size = 30\n",
        "shuffle_batch_size = 1000\n",
        "dataset2 = windowed_dataset(series_train,window_size,batch_size,shuffle_batch_size)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                                                           strides=1, padding='causal',\n",
        "                                                           activation='relu', input_shape=[None,1]),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "                                    tf.keras.layers.Dense(1),\n",
        "                                    tf.keras.layers.Lambda(lambda x: x*100)])\n",
        "\n",
        "model.compile(loss = 'mse', optimizer= tf.keras.optimizers.SGD(lr=1e-5 ,momentum = 0.9))\n",
        "model.fit(dataset2,epochs = 1001, steps_per_epoch=1)\n",
        "\n",
        "rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odZVeGSMDHyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sunspots model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                      strides=1, padding=\"causal\",\n",
        "                      activation=\"relu\",\n",
        "                      input_shape=[None, 1]),\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}